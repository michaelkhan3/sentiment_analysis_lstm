{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import numpy as np\n",
    "import string\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words = pd.read_table(\"glove_word2Vec/glove.6B/glove.6B.50d.txt\", sep=\" \", index_col=0, header=None, quoting=csv.QUOTE_NONE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wordsVector = words.as_matrix()\n",
    "wordsList = words.index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(wordsVector.shape)\n",
    "print(len(wordsList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "type(wordsList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "baseballIndex = wordsList.index('baseball')\n",
    "wordsVector[baseballIndex]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "maxSeqLength = 10\n",
    "numDimensions = 300\n",
    "\n",
    "firstSentence = np.zeros((maxSeqLength), dtype='int32')\n",
    "firstSentence[0] = wordsList.index(\"i\")\n",
    "firstSentence[1] = wordsList.index(\"tought\")\n",
    "firstSentence[2] = wordsList.index(\"the\")\n",
    "firstSentence[3] = wordsList.index(\"movie\")\n",
    "firstSentence[4] = wordsList.index(\"was\")\n",
    "firstSentence[5] = wordsList.index(\"incredible\")\n",
    "firstSentence[6] = wordsList.index(\"and\")\n",
    "firstSentence[7] = wordsList.index(\"inspiring\")\n",
    "print(firstSentence.shape)\n",
    "print(firstSentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting sentences\n",
    "\n",
    " Creating a utility function to convert sentences into an numpy array of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_sentence(sentence):\n",
    "    # Got from analysis below.\n",
    "    maxSeqLength = 250\n",
    "    index_count = 0\n",
    "    \n",
    "    remove_special_chars = re.compile(\"[^A-Za-z0-9 ]+\")\n",
    "    \n",
    "    sentence = sentence.lower()\n",
    "    sentence = sentence.translate(string.punctuation)\n",
    "    sentence = re.sub(remove_special_chars, \"\", sentence)\n",
    "    sentence = sentence.split(\" \")\n",
    "    if len(sentence) > maxSeqLength:\n",
    "        sentence = sentence[:maxSeqLength]\n",
    "    sentenceList = np.zeros((maxSeqLength), dtype='int32')\n",
    "    for word in sentence:\n",
    "        try:\n",
    "            sentenceList[index_count] = wordsList.index(word)\n",
    "        except ValueError:\n",
    "            # TODO create a vector for unknow words\n",
    "            # https://groups.google.com/forum/#!topic/globalvectors/n6BYywiENGo\n",
    "            # For now just skip unkown words\n",
    "            sentenceList[index_count] = 0\n",
    "            \n",
    "        index_count = index_count + 1\n",
    "        \n",
    "    return np.array(sentenceList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testSent = \"Hello, how are you doing today?\"\n",
    "\n",
    "testSentVec = convert_sentence(testSent)\n",
    "\n",
    "print(testSentVec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    print(tf.nn.embedding_lookup(wordsVector, firstSentence).eval().shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "\n",
    "Now we will load the movie review data. \n",
    "The data comes from https://www.kaggle.com/c/word2vec-nlp-tutorial/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_reviews = pd.read_table(\"movie_review_dataset/labeledTrainData/labeledTrainData.tsv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_reviews.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Exploratory analysis\n",
    "\n",
    "Exploring the number of words in each review "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sentence_len(sentence):\n",
    "    sentence = sentence.translate(string.punctuation)\n",
    "    sentence = sentence.split(\" \")\n",
    "    return len(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_words = train_reviews.apply(lambda row: sentence_len(row['review']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_words.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.hist(num_words, 50)\n",
    "plt.xlabel(\"Sentence Length\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.axis([0, 1200, 0, 8000])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting words to word vecs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TODO\n",
    "\n",
    "We may have to have all reviews be of the same length. This is kind of inconvinient since we will lose information.\n",
    "Check if anyone has a solution to this.\n",
    "\n",
    "##### UPDATE 6/12/2017\n",
    "Now that we end up with a list of lists from this conversion, it may be possible to have the internal lists be of different length. Because I am converting the list to a DataFrame I wont try to have different lengths yet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, try this with a subset of the training data. Maybe the first 500 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subset_reviews = train_reviews.iloc[0:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#subset_reviews_ids = subset_reviews.apply(lambda row: convert_sentence(row['review']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subset_reviews_ids = [convert_sentence(row['review']) for index, row in subset_reviews.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subset_reviews_ids = pd.DataFrame(subset_reviews_ids)\n",
    "subset_reviews_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subset_reviews_ids.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_reviews_ids = train_reviews.apply(lambda row: convert_sentence(row['review']), axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
