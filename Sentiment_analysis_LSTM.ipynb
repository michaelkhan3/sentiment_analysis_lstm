{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import numpy as np\n",
    "import string\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words = pd.read_table(\"glove_word2Vec/glove.6B/glove.6B.50d.txt\", sep=\" \", index_col=0, header=None, quoting=csv.QUOTE_NONE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wordsVector = words.as_matrix().astype(np.float32)\n",
    "wordsList = words.index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400000, 50)\n",
      "400000\n"
     ]
    }
   ],
   "source": [
    "print(wordsVector.shape)\n",
    "print(len(wordsList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.93270004,  1.04209995, -0.78514999,  0.91033   ,  0.22711   ,\n",
       "       -0.62158   , -1.64929998,  0.07686   , -0.58679998,  0.058831  ,\n",
       "        0.35628   ,  0.68915999, -0.50598001,  0.70472997,  1.26639998,\n",
       "       -0.40031001, -0.020687  ,  0.80862999, -0.90565997, -0.074054  ,\n",
       "       -0.87674999, -0.62910002, -0.12684999,  0.11524   , -0.55685002,\n",
       "       -1.68260002, -0.26291001,  0.22632   ,  0.713     , -1.08280003,\n",
       "        2.12310004,  0.49869001,  0.066711  , -0.48225999, -0.17896999,\n",
       "        0.47699001,  0.16384   ,  0.16537   , -0.11506   , -0.15962   ,\n",
       "       -0.94926   , -0.42833   , -0.59456998,  1.35660005, -0.27506   ,\n",
       "        0.19918001, -0.36008   ,  0.55667001, -0.70314997,  0.17157   ], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseballIndex = wordsList.index('baseball')\n",
    "wordsVector[baseballIndex]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10,)\n",
      "[    41 305234      0   1005     15   7446      5  13767      0      0]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "maxSeqLength = 10\n",
    "numDimensions = 300\n",
    "\n",
    "firstSentence = np.zeros((maxSeqLength), dtype='int32')\n",
    "firstSentence[0] = wordsList.index(\"i\")\n",
    "firstSentence[1] = wordsList.index(\"tought\")\n",
    "firstSentence[2] = wordsList.index(\"the\")\n",
    "firstSentence[3] = wordsList.index(\"movie\")\n",
    "firstSentence[4] = wordsList.index(\"was\")\n",
    "firstSentence[5] = wordsList.index(\"incredible\")\n",
    "firstSentence[6] = wordsList.index(\"and\")\n",
    "firstSentence[7] = wordsList.index(\"inspiring\")\n",
    "print(firstSentence.shape)\n",
    "print(firstSentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting sentences\n",
    "\n",
    " Creating a utility function to convert sentences into an numpy array of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "maxSeqLength = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_sentence(sentence):\n",
    "    # Got from analysis below.\n",
    "    maxSeqLength = 250\n",
    "    index_count = 0\n",
    "    \n",
    "    remove_special_chars = re.compile(\"[^A-Za-z0-9 ]+\")\n",
    "    \n",
    "    sentence = sentence.lower()\n",
    "    sentence = sentence.translate(string.punctuation)\n",
    "    sentence = re.sub(remove_special_chars, \"\", sentence)\n",
    "    sentence = sentence.split(\" \")\n",
    "    if len(sentence) > maxSeqLength:\n",
    "        sentence = sentence[:maxSeqLength]\n",
    "    sentenceList = np.zeros((maxSeqLength), dtype='int32')\n",
    "    for word in sentence:\n",
    "        try:\n",
    "            sentenceList[index_count] = wordsList.index(word)\n",
    "        except ValueError:\n",
    "            # TODO create a vector for unknow words\n",
    "            # https://groups.google.com/forum/#!topic/globalvectors/n6BYywiENGo\n",
    "            # For now just skip unkown words\n",
    "            sentenceList[index_count] = 0\n",
    "            \n",
    "        index_count = index_count + 1\n",
    "        \n",
    "    return np.array(sentenceList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13075   197    32    81   914   373     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0]\n"
     ]
    }
   ],
   "source": [
    "testSent = \"Hello, how are you doing today?\"\n",
    "\n",
    "testSentVec = convert_sentence(testSent)\n",
    "\n",
    "print(testSentVec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 50)\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    print(tf.nn.embedding_lookup(wordsVector, firstSentence).eval().shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "\n",
    "Now we will load the movie review data. \n",
    "The data comes from https://www.kaggle.com/c/word2vec-nlp-tutorial/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_reviews = pd.read_table(\"movie_review_dataset/labeledTrainData/labeledTrainData.tsv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5814_8</td>\n",
       "      <td>1</td>\n",
       "      <td>With all this stuff going down at the moment w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2381_9</td>\n",
       "      <td>1</td>\n",
       "      <td>\\The Classic War of the Worlds\\\" by Timothy Hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7759_3</td>\n",
       "      <td>0</td>\n",
       "      <td>The film starts with a manager (Nicholas Bell)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3630_4</td>\n",
       "      <td>0</td>\n",
       "      <td>It must be assumed that those who praised this...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9495_8</td>\n",
       "      <td>1</td>\n",
       "      <td>Superbly trashy and wondrously unpretentious 8...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  sentiment                                             review\n",
       "0  5814_8          1  With all this stuff going down at the moment w...\n",
       "1  2381_9          1  \\The Classic War of the Worlds\\\" by Timothy Hi...\n",
       "2  7759_3          0  The film starts with a manager (Nicholas Bell)...\n",
       "3  3630_4          0  It must be assumed that those who praised this...\n",
       "4  9495_8          1  Superbly trashy and wondrously unpretentious 8..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_reviews.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Exploratory analysis\n",
    "\n",
    "Exploring the number of words in each review "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sentence_len(sentence):\n",
    "    sentence = sentence.translate(string.punctuation)\n",
    "    sentence = sentence.split(\" \")\n",
    "    return len(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_words = train_reviews.apply(lambda row: sentence_len(row['review']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    25000.000000\n",
       "mean       233.786240\n",
       "std        173.745845\n",
       "min         10.000000\n",
       "25%        127.000000\n",
       "50%        174.000000\n",
       "75%        284.000000\n",
       "max       2470.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_words.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZcAAAEKCAYAAADenhiQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb5dd70b898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.hist(num_words, 50)\n",
    "plt.xlabel(\"Sentence Length\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.axis([0, 1200, 0, 8000])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting words to word vecs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code in this section has been commented out as it takes quite alot of time to run it.\n",
    "Instead we can just load data from a csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TODO\n",
    "\n",
    "We may have to have all reviews be of the same length. This is kind of inconvinient since we will lose information.\n",
    "Check if anyone has a solution to this.\n",
    "\n",
    "##### UPDATE 6/12/2017\n",
    "Now that we end up with a list of lists from this conversion, it may be possible to have the internal lists be of different length. Because I am converting the list to a DataFrame I wont try to have different lengths yet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, try this with a subset of the training data. Maybe the first 500 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# subset_reviews = train_reviews.iloc[0:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using apply wasn't working correctly so I decided to use a list comprehension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# subset_reviews_ids = [convert_sentence(row[3]) for row in subset_reviews.itertuples()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# subset_reviews_ids = pd.DataFrame(subset_reviews_ids)\n",
    "# subset_reviews_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# subset_reviews_ids.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now apply it to whole dataset. \n",
    "\n",
    "This takes a **LONG** time to run therefore, I have saved the output file as a csv which can loaded to skip this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train_reviews_ids = [convert_sentence(row[3]) for row in train_reviews.itertuples()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train_reviews_ids_df = pd.DataFrame(train_reviews_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train_reviews_ids_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train_reviews_ids_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train_reviews_ids_df.to_csv(\"movie_review_dataset/labeledTrainData/ids_matrix.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TODO: remove drop once new version of csv is created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_reviews_ids_df = pd.read_csv(\"movie_review_dataset/labeledTrainData/ids_matrix.csv\").drop(['Unnamed: 0'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 24\n",
    "lstm_units = 64\n",
    "num_classes = 2\n",
    "itterations = 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.reset_default_graph()\n",
    "\n",
    "labels = tf.placeholder(tf.float32, [batch_size, num_classes])\n",
    "input_data = tf.placeholder(tf.int32, [batch_size, maxSeqLength])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = tf.Variable(tf.zeros([batch_size, maxSeqLength, numDimensions]), dtype=tf.float32)\n",
    "\n",
    "data = tf.nn.embedding_lookup(wordsVector, input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lstm_cell = tf.contrib.rnn.BasicLSTMCell(lstm_units)\n",
    "lstm_cell = tf.contrib.rnn.DropoutWrapper(cell=lstm_cell, output_keep_prob=0.75)\n",
    "value, _ = tf.nn.dynamic_rnn(lstm_cell, data, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weight = tf.Variable(tf.truncated_normal([lstm_units, num_classes]))\n",
    "bias = tf.Variable(tf.constant(0.1, shape=[num_classes]))\n",
    "value = tf.transpose(value, [1, 0, 2])\n",
    "last = tf.gather(value, int(value.get_shape()[0]) - 1)\n",
    "prediction = (tf.matmul(last, weight) + bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correctPred = tf.equal(tf.argmax(prediction, 1), tf.argmax(labels,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correctPred, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=prediction, labels=labels))\n",
    "optimizer = tf.train.AdamOptimizer().minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "tf.summary.scalar('Loss', loss)\n",
    "tf.summary.scalar('Accuracy', accuracy)\n",
    "merged = tf.summary.merge_all()\n",
    "logdir = \"tensorboard/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") + \"/\"\n",
    "writer = tf.summary.FileWriter(logdir, sess.graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Train Network\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing for functions  -  Delete later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_reviews.head()\n",
    "train_reviews.iloc[1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>240</th>\n",
       "      <th>241</th>\n",
       "      <th>242</th>\n",
       "      <th>243</th>\n",
       "      <th>244</th>\n",
       "      <th>245</th>\n",
       "      <th>246</th>\n",
       "      <th>247</th>\n",
       "      <th>248</th>\n",
       "      <th>249</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17</td>\n",
       "      <td>64</td>\n",
       "      <td>37</td>\n",
       "      <td>3496</td>\n",
       "      <td>222</td>\n",
       "      <td>135</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>1600</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>18</td>\n",
       "      <td>38</td>\n",
       "      <td>14</td>\n",
       "      <td>10485</td>\n",
       "      <td>1603</td>\n",
       "      <td>34339</td>\n",
       "      <td>100</td>\n",
       "      <td>41</td>\n",
       "      <td>113442</td>\n",
       "      <td>1881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2392</td>\n",
       "      <td>136</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6965</td>\n",
       "      <td>21</td>\n",
       "      <td>7842</td>\n",
       "      <td>20457</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>319</td>\n",
       "      <td>2383</td>\n",
       "      <td>17</td>\n",
       "      <td>7</td>\n",
       "      <td>865</td>\n",
       "      <td>5616</td>\n",
       "      <td>2913</td>\n",
       "      <td>1227</td>\n",
       "      <td>3143</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>23912</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>23243</td>\n",
       "      <td>46</td>\n",
       "      <td>23236</td>\n",
       "      <td>74</td>\n",
       "      <td>3411</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>390</td>\n",
       "      <td>30</td>\n",
       "      <td>4656</td>\n",
       "      <td>12</td>\n",
       "      <td>155</td>\n",
       "      <td>38</td>\n",
       "      <td>3490</td>\n",
       "      <td>37</td>\n",
       "      <td>319</td>\n",
       "      <td>...</td>\n",
       "      <td>74688</td>\n",
       "      <td>285</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2496</td>\n",
       "      <td>53</td>\n",
       "      <td>1071</td>\n",
       "      <td>33</td>\n",
       "      <td>4</td>\n",
       "      <td>2365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30566</td>\n",
       "      <td>53332</td>\n",
       "      <td>5</td>\n",
       "      <td>136455</td>\n",
       "      <td>45659</td>\n",
       "      <td>15835</td>\n",
       "      <td>10534</td>\n",
       "      <td>72004</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>359</td>\n",
       "      <td>592</td>\n",
       "      <td>2219</td>\n",
       "      <td>8558</td>\n",
       "      <td>14</td>\n",
       "      <td>106212</td>\n",
       "      <td>21809</td>\n",
       "      <td>0</td>\n",
       "      <td>5230</td>\n",
       "      <td>1432</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 250 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0      1     2       3      4      5      6      7      8     9  ...   \\\n",
       "0     17     64    37    3496    222    135     22      0   1600    17  ...    \n",
       "1      0   2392   136       3      0   6965     21   7842  20457    14  ...    \n",
       "2      0    319  2383      17      7    865   5616   2913   1227  3143  ...    \n",
       "3     20    390    30    4656     12    155     38   3490     37   319  ...    \n",
       "4  30566  53332     5  136455  45659  15835  10534  72004      0     0  ...    \n",
       "\n",
       "     240    241   242    243    244     245    246  247     248   249  \n",
       "0     18     38    14  10485   1603   34339    100   41  113442  1881  \n",
       "1      0      0     0      0      0       0      0    0       0     0  \n",
       "2      0  23912     0      5  23243      46  23236   74    3411     0  \n",
       "3  74688    285     6      0   2496      53   1071   33       4  2365  \n",
       "4    359    592  2219   8558     14  106212  21809    0    5230  1432  \n",
       "\n",
       "[5 rows x 250 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_reviews_ids_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24999"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train_reviews_ids_df.shape[0]-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    19      7    139    685     47     29  12965      4    269     12\n",
      "    1318     15   1403   1136      4   1711     37      0  30410    504\n",
      "       0    853     12      0    369     15     48      3      0   2601\n",
      "      10      0    929  52729  19367   6571     37   1072      4      0\n",
      "     281     14  18615      0    929    281     15    243     13   2245\n",
      "    4490     59      7    300     38     15      7    353   6620    329\n",
      "       5   9172      7    300     38    334      7    426    542      6\n",
      "   12775      0    299      3    250   5812      6    139      0  30410\n",
      "       0   2219      3     37    319    212     14    936     34  86071\n",
      "   27020     25      0   2389      3      0   3401     21      7   1541\n",
      "      12     31    848      4  15114    108      0      0  30410    110\n",
      "    5207   7538      5   1793 107928     32    219   3826    102     14\n",
      "     684  62557    914    187  19361  15095   7515     17     26    639\n",
      "   30075      5  43425      0  30410     41   1290   5323  14753 105459\n",
      "     266      4   1650     66      3   6997      5    307    531      0\n",
      "    2491      6     44   3293    639  19266   5797     10     84   3456\n",
      "    1247     36     12     37      0     51    130     56   9520     73\n",
      "       0  49171   2219    331     12     15    965  13900     60     49\n",
      "     206  44167      3   4178     22      7  11005   4635    165    111\n",
      "  306854  62562   9723   3221      0   1541      4    498      4     29\n",
      "     685   2984     10     26    182  11495      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0\n",
      "       0      0      0      0      0      0      0      0      0      0]]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "from random import randint\n",
    "\n",
    "test = randint(1, train_reviews_ids_df.shape[0]-1)\n",
    "ans = train_reviews_ids_df[test-1:test].as_matrix()\n",
    "\n",
    "print(ans)\n",
    "print(type(ans))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1.90000000e+01   7.00000000e+00   1.39000000e+02   6.85000000e+02\n",
      "   4.70000000e+01   2.90000000e+01   1.29650000e+04   4.00000000e+00\n",
      "   2.69000000e+02   1.20000000e+01   1.31800000e+03   1.50000000e+01\n",
      "   1.40300000e+03   1.13600000e+03   4.00000000e+00   1.71100000e+03\n",
      "   3.70000000e+01   0.00000000e+00   3.04100000e+04   5.04000000e+02\n",
      "   0.00000000e+00   8.53000000e+02   1.20000000e+01   0.00000000e+00\n",
      "   3.69000000e+02   1.50000000e+01   4.80000000e+01   3.00000000e+00\n",
      "   0.00000000e+00   2.60100000e+03   1.00000000e+01   0.00000000e+00\n",
      "   9.29000000e+02   5.27290000e+04   1.93670000e+04   6.57100000e+03\n",
      "   3.70000000e+01   1.07200000e+03   4.00000000e+00   0.00000000e+00\n",
      "   2.81000000e+02   1.40000000e+01   1.86150000e+04   0.00000000e+00\n",
      "   9.29000000e+02   2.81000000e+02   1.50000000e+01   2.43000000e+02\n",
      "   1.30000000e+01   2.24500000e+03   4.49000000e+03   5.90000000e+01\n",
      "   7.00000000e+00   3.00000000e+02   3.80000000e+01   1.50000000e+01\n",
      "   7.00000000e+00   3.53000000e+02   6.62000000e+03   3.29000000e+02\n",
      "   5.00000000e+00   9.17200000e+03   7.00000000e+00   3.00000000e+02\n",
      "   3.80000000e+01   3.34000000e+02   7.00000000e+00   4.26000000e+02\n",
      "   5.42000000e+02   6.00000000e+00   1.27750000e+04   0.00000000e+00\n",
      "   2.99000000e+02   3.00000000e+00   2.50000000e+02   5.81200000e+03\n",
      "   6.00000000e+00   1.39000000e+02   0.00000000e+00   3.04100000e+04\n",
      "   0.00000000e+00   2.21900000e+03   3.00000000e+00   3.70000000e+01\n",
      "   3.19000000e+02   2.12000000e+02   1.40000000e+01   9.36000000e+02\n",
      "   3.40000000e+01   8.60710000e+04   2.70200000e+04   2.50000000e+01\n",
      "   0.00000000e+00   2.38900000e+03   3.00000000e+00   0.00000000e+00\n",
      "   3.40100000e+03   2.10000000e+01   7.00000000e+00   1.54100000e+03\n",
      "   1.20000000e+01   3.10000000e+01   8.48000000e+02   4.00000000e+00\n",
      "   1.51140000e+04   1.08000000e+02   0.00000000e+00   0.00000000e+00\n",
      "   3.04100000e+04   1.10000000e+02   5.20700000e+03   7.53800000e+03\n",
      "   5.00000000e+00   1.79300000e+03   1.07928000e+05   3.20000000e+01\n",
      "   2.19000000e+02   3.82600000e+03   1.02000000e+02   1.40000000e+01\n",
      "   6.84000000e+02   6.25570000e+04   9.14000000e+02   1.87000000e+02\n",
      "   1.93610000e+04   1.50950000e+04   7.51500000e+03   1.70000000e+01\n",
      "   2.60000000e+01   6.39000000e+02   3.00750000e+04   5.00000000e+00\n",
      "   4.34250000e+04   0.00000000e+00   3.04100000e+04   4.10000000e+01\n",
      "   1.29000000e+03   5.32300000e+03   1.47530000e+04   1.05459000e+05\n",
      "   2.66000000e+02   4.00000000e+00   1.65000000e+03   6.60000000e+01\n",
      "   3.00000000e+00   6.99700000e+03   5.00000000e+00   3.07000000e+02\n",
      "   5.31000000e+02   0.00000000e+00   2.49100000e+03   6.00000000e+00\n",
      "   4.40000000e+01   3.29300000e+03   6.39000000e+02   1.92660000e+04\n",
      "   5.79700000e+03   1.00000000e+01   8.40000000e+01   3.45600000e+03\n",
      "   1.24700000e+03   3.60000000e+01   1.20000000e+01   3.70000000e+01\n",
      "   0.00000000e+00   5.10000000e+01   1.30000000e+02   5.60000000e+01\n",
      "   9.52000000e+03   7.30000000e+01   0.00000000e+00   4.91710000e+04\n",
      "   2.21900000e+03   3.31000000e+02   1.20000000e+01   1.50000000e+01\n",
      "   9.65000000e+02   1.39000000e+04   6.00000000e+01   4.90000000e+01\n",
      "   2.06000000e+02   4.41670000e+04   3.00000000e+00   4.17800000e+03\n",
      "   2.20000000e+01   7.00000000e+00   1.10050000e+04   4.63500000e+03\n",
      "   1.65000000e+02   1.11000000e+02   3.06854000e+05   6.25620000e+04\n",
      "   9.72300000e+03   3.22100000e+03   0.00000000e+00   1.54100000e+03\n",
      "   4.00000000e+00   4.98000000e+02   4.00000000e+00   2.90000000e+01\n",
      "   6.85000000e+02   2.98400000e+03   1.00000000e+01   2.60000000e+01\n",
      "   1.82000000e+02   1.14950000e+04   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00]\n",
      "[1, 0]\n"
     ]
    }
   ],
   "source": [
    "a, b = getTrainBatch()\n",
    "\n",
    "print(a[0])\n",
    "print(b[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing for functions  -  Delete later ABOVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from random import randint\n",
    "\n",
    "# Helper functions to provide data for batch\n",
    "def getTrainBatch():\n",
    "    labels = []\n",
    "    arr = np.zeros([batch_size, maxSeqLength])\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        num = randint(1, train_reviews_ids_df.shape[0]-1)\n",
    "        arr[i] = train_reviews_ids_df[test-1:test].as_matrix()\n",
    "        labels.append([1, 0]) if train_reviews.iloc[i, 1] == 1 else labels.append([0, 1])\n",
    "    \n",
    "    return arr, labels\n",
    "\n",
    "def getTestBatch():\n",
    "    labels = []\n",
    "    arr = np.zeros([batch_size, maxSeqLength])\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        num = randint(1, train_reviews_ids_df.shape[0]-1)\n",
    "        arr[i] = train_reviews_ids_df[test-1:test].as_matrix()\n",
    "        labels.append([1, 0]) if train_reviews.iloc[i, 1] == 1 else labels.append([0, 1])\n",
    "    print(\"TEST DATA HAS NOT BEEN LOADED YET\")\n",
    "    # TODO: Load test data and do same prep as training data\n",
    "    return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Saver' object has no attribute 'saver'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-d5ed61bf81e8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m#Save the network every 10,000 training iterations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m10000\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0msave_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"models/pretrained_lstm.ckpt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"saved to %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0msave_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Saver' object has no attribute 'saver'"
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "saver = tf.train.Saver()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for i in range(itterations):\n",
    "    # Get next batch of reviews\n",
    "    nextBatch, nextBatchLabels = getTrainBatch()\n",
    "    sess.run(optimizer, {input_data: nextBatch, labels: nextBatchLabels})\n",
    "    \n",
    "    #Write summary to Tensorboard\n",
    "    if (i % 50 == 0):\n",
    "        summary = sess.run(merged, {input_data: nextBatch, labels: nextBatchLabels})\n",
    "        writer.add_summary(summary, i)\n",
    "        \n",
    "    #Save the network every 10,000 training iterations\n",
    "    if(i % 10000 == 0 and i != 0):\n",
    "        save_path = saver.save(sess, \"models/pretrained_lstm.ckpt\", global_step = 1)\n",
    "        print(\"saved to %s\" % save_path)\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
